---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a Machine Learning Research Engineer with 6+ years of experience developing production ML systems for federal agencies and research institutions. I'm currently transitioning from applied ML to fundamental AI research, with particular interests in model optimization, mechanistic interpretability, and reinforcement learning.

## Background

I've spent my career at the intersection of machine learning, physics, and applied mathematics:

- **Booz Allen Hamilton** (2024-Present) - Cyber ML Engineer developing APT detection systems and anomaly detection pipelines
- **RAND Corporation** (2022-2023) - Technical Analyst focusing on ML safety, climate AI, and cybersecurity. **Awarded RAND Innovation Award** for pioneering MLOps capabilities
- **Brookhaven National Laboratory** (2021) - Developed NLP tools for malware analysis and graph-based detection systems
- **FBI** (2017-2018) - Honors Intern in Cybersecurity developing automation tools for large-scale network analysis

## Education & Research

**Degrees:**
- M.S. in Applied Mathematics & Statistics (Computational & Systems Biology) - Stony Brook University (2021)
- M.S. in Physics - Seton Hall University (2020)
- B.S. in Mathematics - Seton Hall University (2018)

**Current Research Projects:**
- **TNDâ€“MultiRenewal**: Hierarchical renewal model for influenza/RSV/COVID-19 using neural lag-kernel estimation (manuscript in prep for *PLOS Computational Biology*)
- **Spectral Deformations in Near-Extremal Kerr Black Holes**: First-order shifts in superradiant modes (draft for *Physical Review D*)
- **AlphaCT: RL Optimization with Formal Guarantees**

Extending AlphaDev-style RL to security-critical cryptographic code with formal constant-time verification. 

**Key Innovation:** First framework integrating RL optimization with formal proofs and adversarial robustness testing for crypto kernels.

**[View Full Proposal on GitHub â†’](https://github.com/joshuasteier/AlphaCT)**

**Technical Highlights:**
- RL with in-loop constant-time constraints
- Binary-level verification + empirical leakage testing
- Adversarial self-play across compilers/microarchitectures
- Target: Post-quantum crypto (Kyber/Dilithium), oblivious primitives

**Status:** Research proposal stage, seeking collaboration and feedback from RL, formal methods, and cryptographic engineering communities.

**Publications:** 15+ peer-reviewed papers and institutional reports, including work published in *Applied Physics Letters*, RAND Corporation reports, and AAAI proceedings. Papers under review at *Integers*, *ACM TEAC*, and *Discrete Applied Mathematics*.

**Active Reviewer:** *Discrete Applied Mathematics*, *Machine Learning with Applications*, ICLR workshops

## The Pivot to Research

While I'm proud of my applied work, I'm increasingly drawn to fundamental questions:
- How can we make models radically more efficient without losing capability?
- What are neural networks actually learning, and can we understand their internal representations?
- What are the theoretical limits of current ML approaches?

I'm now executing an aggressive research pivot by:

1. **Implementing foundational papers** from scratch in JAX to deeply understand design choices
2. **Contributing to open-source** ML frameworks (PyTorch, JAX ecosystem)
3. **Running original experiments** and documenting findings publicly
4. **Building toward research engineering roles** at top AI labs (DeepMind, Anthropic, OpenAI)

## Recent Work

I'm currently implementing "Attention Is All You Need" in JAX, documenting every detail that papers gloss over. Follow my progress:

- **GitHub:** [github.com/joshuasteier](https://github.com/joshuasteier)
- **Blog:** [Recent posts](/year-archive/)
- **Full CV:** [Download PDF](/cv/)

---

**I'm actively seeking research engineering roles at AI research labs.** If you're working on fundamental ML problems or have advice for someone making this transition, I'd love to connect:

ðŸ“§ [joshsteier@gmail.com](mailto:joshsteier@gmail.com)  
ðŸ’¼ [LinkedIn](https://linkedin.com/in/joshuasteier)  
ðŸ’» [GitHub](https://github.com/joshuasteier)
